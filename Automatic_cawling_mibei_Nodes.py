# å¯¼å…¥å¿…è¦çš„æ ‡å‡†åº“æ¨¡å—
import os  # æ“ä½œç³»ç»Ÿæ¥å£ï¼Œç”¨äºæ–‡ä»¶è·¯å¾„æ“ä½œ
import re  # æ­£åˆ™è¡¨è¾¾å¼ï¼Œç”¨äºæ–‡æœ¬æ¨¡å¼åŒ¹é…
import sys  # ç³»ç»Ÿç›¸å…³åŠŸèƒ½ï¼Œå¦‚é€€å‡ºç¨‹åº
import time  # æ—¶é—´ç›¸å…³åŠŸèƒ½ï¼Œå¦‚å»¶æ—¶
import random  # éšæœºæ•°ç”Ÿæˆ
import requests  # HTTPè¯·æ±‚åº“
import subprocess  # å­è¿›ç¨‹ç®¡ç†
import psutil  # è¿›ç¨‹å’Œç³»ç»Ÿå·¥å…·åº“
import json  # JSONæ•°æ®å¤„ç†
import base64  # Base64ç¼–ç è§£ç 
import socket  # ç½‘ç»œè¿æ¥
from bs4 import BeautifulSoup  # HTMLè§£æåº“
from datetime import datetime  # æ—¥æœŸæ—¶é—´å¤„ç†
import logging  # æ—¥å¿—è®°å½•
from typing import Optional, List, Dict, Any  # ç±»å‹æ³¨è§£

# === é«˜çº§é»‘å®¢æ¨¡å—å¯¼å…¥ ===
try:
    import aiohttp  # å¼‚æ­¥HTTPè¯·æ±‚
    import asyncio  # å¼‚æ­¥ç¼–ç¨‹åº“
    import aiofiles  # å¼‚æ­¥æ–‡ä»¶æ“ä½œ
    has_async = True
except ImportError:
    logging.warning("ğŸš« å¼‚æ­¥æ¨¡å—æœªå®‰è£…ï¼Œå°†ä½¿ç”¨åŒæ­¥æ¨¡å¼è¿è¡Œ")
    has_async = False

try:
    import win32api
    import win32process
    import win32con
    has_win32 = True
except ImportError:
    logging.warning("ğŸš« win32æ¨¡å—æœªå®‰è£…ï¼Œè¿›ç¨‹éšè—åŠŸèƒ½å—é™")
    has_win32 = False


# === é…ç½®ç±» ===
class Config:
    """ç¨‹åºå…¨å±€é…ç½®ç±» - é»‘å®¢æ¨¡å¼"""
    BASE_DIR = os.path.dirname(os.path.abspath(__file__))  # è·å–è„šæœ¬æ‰€åœ¨ç›®å½•ç»å¯¹è·¯å¾„
    V2RAYN_EXE = "v2rayN.exe"  # v2rayNå¯æ‰§è¡Œæ–‡ä»¶å
    CONFIG_FILE = "config.json"  # v2rayNé…ç½®æ–‡ä»¶åç§°
    NODES_FILE = "nodes.txt"  # èŠ‚ç‚¹ä¿¡æ¯ä¿å­˜æ–‡ä»¶å
    CHECK_TIMEOUT = 10  # è¿›ç¨‹æ£€æŸ¥è¶…æ—¶æ—¶é—´(ç§’)
    MAIN_URL = 'https://www.mibei77.com/'  # ç›®æ ‡ç½‘ç«™ä¸»URL
    
    # ğŸ”¥ æ€§èƒ½ä¼˜åŒ–é…ç½®
    MAX_CONCURRENT_REQUESTS = 20  # æœ€å¤§å¹¶å‘è¯·æ±‚æ•°
    CONNECTION_TIMEOUT = 10  # è¿æ¥è¶…æ—¶æ—¶é—´
    RETRY_ATTEMPTS = 3  # æœ€å¤§é‡è¯•æ¬¡æ•°
    
    # ğŸ›¡ï¸ éšè”½æ€§é…ç½®
    ENABLE_STEALTH = True  # å¯ç”¨éšèº«æ¨¡å¼
    ENABLE_FAKE_LOGGING = True  # å¯ç”¨è¿·æƒ‘æ€§æ—¥å¿—
    MIN_DELAY = 1.0  # æœ€å°å»¶æ—¶(ç§’)
    MAX_DELAY = 3.0  # æœ€å¤§å»¶æ—¶(ç§’)
    
    # ğŸ“Š èŠ‚ç‚¹ç­›é€‰é…ç½®
    ENABLE_NODE_BENCHMARK = True  # å¯ç”¨èŠ‚ç‚¹æµ‹é€Ÿ
    BENCHMARK_THRESHOLD = 1000  # å»¶è¿Ÿé˜ˆå€¼(æ¯«ç§’)
    TOP_NODES_PERCENTAGE = 20  # ä¿ç•™å‰20%çš„èŠ‚ç‚¹
    
    # æ–°å¢é…ç½®é¡¹
    MAX_NODES = 250  # æœ€å¤§èŠ‚ç‚¹æ•°é‡
    ENABLE_NODE_FILTERING = True  # å¯ç”¨èŠ‚ç‚¹ç­›é€‰
    ENABLE_SPEED_TEST = True  # å¯ç”¨æµ‹é€Ÿ
    MAX_LATENCY = 1000  # æœ€å¤§å»¶è¿Ÿ(ms)
    IGNORE_LATENCY_TEST = False  # æ˜¯å¦å¿½ç•¥æµ‹é€Ÿ
    
    # ğŸ•µï¸ é«˜çº§éšè”½é…ç½®
    ENABLE_ADVANCED_STEALTH = True  # å¯ç”¨é«˜çº§éšèº«
    RANDOMIZE_FILENAMES = True  # éšæœºåŒ–ç”Ÿæˆçš„æ–‡ä»¶å
    CLEANUP_TEMP_FILES = True  # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    
    # ğŸ“ˆ æ€§èƒ½è°ƒä¼˜
    MAX_MEMORY_USAGE = 512  # æœ€å¤§å†…å­˜ä½¿ç”¨(MB)
    ENABLE_AUTO_OPTIMIZE = True  # å¯ç”¨è‡ªåŠ¨ä¼˜åŒ–
    
    # ğŸ”§ è°ƒè¯•é…ç½®
    ENABLE_DEBUG_LOGGING = False  # å¯ç”¨è°ƒè¯•æ—¥å¿—
    LOG_SENSITIVE_INFO = False  # æ˜¯å¦è®°å½•æ•æ„Ÿä¿¡æ¯
    
    # ğŸŒ é«˜è´¨é‡ç”¨æˆ·ä»£ç†åˆ—è¡¨ - æ¨¡æ‹ŸçœŸå®æµè§ˆå™¨æŒ‡çº¹
    USER_AGENTS = [
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36",
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Firefox/113.0 Safari/537.36",
        "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/16.4 Safari/605.1.15",
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Edge/114.0.1823.67 Safari/537.36",
        "Mozilla/5.0 (Linux; Android 13; SM-G998B) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Mobile Safari/537.36"
    ]
    
    # ğŸ“± å®Œæ•´HTTPè¯·æ±‚å¤´ - æ¨¡æ‹ŸçœŸå®æµé‡ç‰¹å¾
    FULL_HEADERS = {
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8',
        'Accept-Language': 'zh-CN,zh;q=0.8,zh-TW;q=0.7,zh-HK;q=0.5,en-US;q=0.3,en;q=0.2',
        'Accept-Encoding': 'gzip, deflate, br',
        'Connection': 'keep-alive',
        'Upgrade-Insecure-Requests': '1',
        'Cache-Control': 'max-age=0',
        'TE': 'trailers',
        'Pragma': 'no-cache'
    }
    
    # ğŸ­ è¿·æƒ‘æ€§æ—¥å¿—æ¶ˆæ¯
    FAKE_LOG_MESSAGES = [
        "æ­£åœ¨æ£€æŸ¥ç³»ç»Ÿæ›´æ–°...",
        "æ¸…ç†ä¸´æ—¶æ–‡ä»¶ä¸­...",
        "ä¼˜åŒ–ç½‘ç»œè®¾ç½®...",
        "æ‰«æç³»ç»Ÿå®‰å…¨...",
        "å¤‡ä»½ç”¨æˆ·æ•°æ®...",
        "æ ¡å‡†ç³»ç»Ÿæ—¶é—´...",
        "åŒæ­¥ç½‘ç»œé…ç½®...",
        "æ£€æŸ¥ç¡¬ä»¶çŠ¶æ€..."
    ]


# === æ—¥å¿—è®¾ç½® ===
def setup_logging():
    """é…ç½®æ—¥å¿—è®°å½•ç³»ç»Ÿ"""
    logging.basicConfig(
        level=logging.INFO,  # è®¾ç½®æ—¥å¿—çº§åˆ«ä¸ºINFO
        format='%(asctime)s - %(levelname)s - %(message)s',  # æ—¥å¿—æ ¼å¼
        handlers=[  # æ—¥å¿—å¤„ç†å™¨
            logging.FileHandler(os.path.join(Config.BASE_DIR, 'v2ray_updater.log')),  # æ–‡ä»¶æ—¥å¿—
            logging.StreamHandler()  # æ§åˆ¶å°æ—¥å¿—
        ]
    )


# === å·¥å…·å‡½æ•° ===

# ğŸ­ è¿·æƒ‘æ€§æ—¥å¿—ç”Ÿæˆå™¨
def fake_logging():
    """ç”Ÿæˆè¿·æƒ‘æ€§æ—¥å¿—ï¼Œè®©ç›‘æ§æ‘¸ä¸ç€å¤´è„‘"""
    if Config.ENABLE_FAKE_LOGGING and random.random() < 0.3:
        logging.info(random.choice(Config.FAKE_LOG_MESSAGES))

# ğŸ”’ éšèº«è¯·æ±‚å¤´ç”Ÿæˆå™¨
def get_stealth_headers() -> Dict[str, str]:
    """ç”Ÿæˆæ›´éšè”½çš„å®Œæ•´è¯·æ±‚å¤´ï¼Œæ¨¡æ‹ŸçœŸå®æµè§ˆå™¨è¡Œä¸º
    
    è¿”å›:
        Dict[str, str]: åŒ…å«å®Œæ•´æµè§ˆå™¨æŒ‡çº¹çš„è¯·æ±‚å¤´
    """
    headers = Config.FULL_HEADERS.copy()
    headers['User-Agent'] = random.choice(Config.USER_AGENTS)
    
    # éšæœºæ·»åŠ ä¸€äº›å¸¸è§ä½†éå¿…è¦çš„è¯·æ±‚å¤´ï¼Œå¢åŠ çœŸå®æ€§
    if random.random() < 0.5:
        headers['DNT'] = '1'  # Do Not Track
    if random.random() < 0.3:
        headers['Sec-Fetch-Dest'] = 'document'
        headers['Sec-Fetch-Mode'] = 'navigate'
        headers['Sec-Fetch-Site'] = 'none'
        headers['Sec-Fetch-User'] = '?1'
    
    return headers

# ğŸ›¡ï¸ æ™ºèƒ½é‡è¯•è£…é¥°å™¨
def smart_retry(max_retries=Config.RETRY_ATTEMPTS):
    """æ›´å®Œå–„çš„æ™ºèƒ½é‡è¯•è£…é¥°å™¨
    
    å‚æ•°:
        max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
    """
    def decorator(func):
        def wrapper(*args, **kwargs):
            last_exception = None
            for attempt in range(max_retries):
                try:
                    # éšæœºå»¶æ—¶ï¼Œé¿å…è¢«è¯†åˆ«ä¸ºæœºå™¨äºº
                    if Config.ENABLE_STEALTH and attempt > 0:
                        sleep_time = (2 ** attempt) + random.uniform(0, 1)
                        logging.info(f"[ğŸ”„] ç¬¬{attempt+1}æ¬¡é‡è¯•ï¼Œç­‰å¾… {sleep_time:.2f} ç§’...")
                        time.sleep(sleep_time)
                    
                    return func(*args, **kwargs)
                except Exception as e:
                    last_exception = e
                    if attempt == max_retries - 1:
                        logging.error(f"[âŒ] æ‰€æœ‰ {max_retries} æ¬¡é‡è¯•éƒ½å¤±è´¥äº†: {e}")
                        raise
                    logging.warning(f"[âš ï¸] ç¬¬ {attempt+1} æ¬¡å°è¯•å¤±è´¥: {e}ï¼Œå‡†å¤‡é‡è¯•...")
            raise last_exception
        return wrapper
    return decorator

# ğŸš€ å¼‚æ­¥è¯·æ±‚å‡½æ•°
async def fetch_page_async(session, url, headers=None):
    """å¼‚æ­¥è·å–é¡µé¢å†…å®¹
    
    å‚æ•°:
        session: aiohttp.ClientSessionå¯¹è±¡
        url: ç›®æ ‡URL
        headers: è¯·æ±‚å¤´
    
    è¿”å›:
        å“åº”å†…å®¹æˆ–None
    """
    if headers is None:
        headers = get_stealth_headers() if Config.ENABLE_STEALTH else get_random_headers()
    
    try:
        # æ¨¡æ‹ŸçœŸäººæ“ä½œçš„éšæœºå»¶æ—¶
        if Config.ENABLE_STEALTH:
            await asyncio.sleep(random.uniform(Config.MIN_DELAY, Config.MAX_DELAY))
        
        async with session.get(url, headers=headers, timeout=Config.CONNECTION_TIMEOUT) as response:
            response.raise_for_status()
            return await response.text()
    except Exception as e:
        logging.error(f"[Ã—] å¼‚æ­¥è¯·æ±‚ {url} å¤±è´¥: {e}")
        return None

# ğŸ“Š å¼‚æ­¥èŠ‚ç‚¹æµ‹é€Ÿ
async def test_node_speed_async(node_info):
    """å¼‚æ­¥æµ‹è¯•èŠ‚ç‚¹å»¶è¿Ÿ
    
    å‚æ•°:
        node_info: èŠ‚ç‚¹ä¿¡æ¯å­—å…¸
    
    è¿”å›:
        åŒ…å«å»¶è¿Ÿä¿¡æ¯çš„å­—å…¸
    """
    start_time = time.time()
    host = node_info.get('address', '')
    port = node_info.get('port', 443)
    
    try:
        # ä½¿ç”¨å¼‚æ­¥socketè¿æ¥æµ‹è¯•
        reader, writer = await asyncio.wait_for(
            asyncio.open_connection(host, port), 
            timeout=3.0
        )
        writer.close()
        await writer.wait_closed()
        latency = (time.time() - start_time) * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
        logging.debug(f"èŠ‚ç‚¹ {host}:{port} å»¶è¿Ÿ: {latency:.2f}ms")
        return {**node_info, 'latency': latency}
    except Exception:
        return {**node_info, 'latency': float('inf')}

def generate_random_string(length: int) -> str:
    """ç”Ÿæˆéšæœºå­—ç¬¦ä¸²ç”¨äºæ··æ·†"""
    import string
    return ''.join(random.choices(string.ascii_letters + string.digits, k=length))

# ğŸ”„ ä¿®å¤å¹¶ä¼˜åŒ–çš„éšæœºè¯·æ±‚å¤´å‡½æ•°
def get_random_headers(stealth=False):
    """ä¿®å¤å‡½æ•°ç­¾åä¸ä¸€è‡´é—®é¢˜"""
    if stealth or Config.ENABLE_STEALTH:
        return get_stealth_headers()
    return {"User-Agent": random.choice(Config.USER_AGENTS)}

# ğŸ¯ æ·±åº¦è¿›ç¨‹éšè—
def create_ghost_process(cmd):
    """åˆ›å»ºå‡ ä¹ä¸å¯è§çš„è¿›ç¨‹
    
    å‚æ•°:
        cmd: è¦æ‰§è¡Œçš„å‘½ä»¤
    
    è¿”å›:
        è¿›ç¨‹å¯¹è±¡
    """
    # è®¾ç½®å¯åŠ¨ä¿¡æ¯
    startupinfo = subprocess.STARTUPINFO()
    startupinfo.dwFlags |= subprocess.STARTF_USESHOWWINDOW
    
    # åŸºæœ¬çš„éšè—å‚æ•°
    creationflags = subprocess.CREATE_NO_WINDOW
    
    # å¦‚æœæœ‰win32æ¨¡å—ï¼Œä½¿ç”¨æ›´é«˜çº§çš„éšè—æŠ€æœ¯
    if has_win32:
        startupinfo.wShowWindow = win32con.SW_HIDE
        creationflags |= (subprocess.IDLE_PRIORITY_CLASS | 
                          win32process.CREATE_BREAKAWAY_FROM_JOB)
    
    # ä½ä¼˜å…ˆçº§è¿è¡Œï¼Œé™ä½å­˜åœ¨æ„Ÿ
    process = subprocess.Popen(
        cmd,
        startupinfo=startupinfo,
        creationflags=creationflags
    )
    return process

# ğŸ”„ è‡ªé€‚åº”çˆ¬å–å™¨
class AdaptiveCrawler:
    """æ ¹æ®ç½‘ç»œçŠ¶å†µæ™ºèƒ½è°ƒæ•´çˆ¬å–ç­–ç•¥"""
    def __init__(self):
        self.success_count = 0
        self.fail_count = 0
        self.last_success_time = None
        self.consecutive_fails = 0
        self.adaptive_interval = 600  # åˆå§‹æ£€æŸ¥é—´éš”
        
    def record_result(self, success: bool):
        """è®°å½•çˆ¬å–ç»“æœ
        
        å‚æ•°:
            success: æ˜¯å¦æˆåŠŸ
        """
        if success:
            self.success_count += 1
            self.last_success_time = datetime.now()
            self.consecutive_fails = 0
            # æˆåŠŸæ—¶ï¼Œé€æ­¥é™ä½æ£€æŸ¥é—´éš”
            self.adaptive_interval = max(300, int(self.adaptive_interval * 0.8))
        else:
            self.fail_count += 1
            self.consecutive_fails += 1
            # å¤±è´¥æ—¶ï¼Œç«‹å³å¢åŠ æ£€æŸ¥é—´éš”
            self.adaptive_interval = min(3600, int(self.adaptive_interval * 1.5))
    
    def record_success(self):
        """è®°å½•æˆåŠŸ"""
        self.record_result(True)
    
    def record_failure(self):
        """è®°å½•å¤±è´¥"""
        self.record_result(False)
    
    def should_crawl(self) -> bool:
        """æ ¹æ®æˆåŠŸç‡åŠ¨æ€è°ƒæ•´æ˜¯å¦çˆ¬å–
        
        è¿”å›:
            æ˜¯å¦åº”è¯¥çˆ¬å–
        """
        # è¿ç»­å¤±è´¥å¤ªå¤šæ¬¡ï¼Œæš‚åœä¸€ä¸‹
        if self.consecutive_fails >= 5:
            logging.warning(f"[!] è¿ç»­å¤±è´¥ {self.consecutive_fails} æ¬¡ï¼Œé™ä½çˆ¬å–é¢‘ç‡")
            return random.random() < 0.1  # 10%çš„æ¦‚ç‡å°è¯•
        
        total = self.success_count + self.fail_count
        if total == 0:
            return True
            
        success_rate = self.success_count / total
        
        # æ ¹æ®æˆåŠŸç‡åŠ¨æ€è°ƒæ•´çˆ¬å–ç­–ç•¥
        if success_rate > 0.8:
            # ç½‘ç»œå¥½ï¼Œå¤§èƒ†çˆ¬
            return True
        elif success_rate > 0.5:
            # ç½‘ç»œä¸€èˆ¬ï¼Œè°¨æ…çˆ¬
            return random.random() > 0.3
        else:
            # ç½‘ç»œå·®ï¼Œå°‘çˆ¬
            return random.random() > 0.7
    
    def get_check_interval(self) -> int:
        """è·å–å½“å‰åº”è¯¥ç­‰å¾…çš„æ—¶é—´é—´éš”
        
        è¿”å›:
            ç­‰å¾…ç§’æ•°
        """
        return self.adaptive_interval

# ğŸ§¹ å†…å­˜ä¼˜åŒ–å™¨ï¼Œé¿å…å†…å­˜æ³„æ¼
class MemoryOptimizer:
    """å†…å­˜ä¼˜åŒ–å™¨ï¼Œé¿å…å†…å­˜æ³„æ¼"""
    def __init__(self):
        self.cleanup_threshold = 100  # æ¯100æ¬¡æ“ä½œæ¸…ç†ä¸€æ¬¡
        self.operation_count = 0
    
    def auto_cleanup(self):
        """è‡ªåŠ¨æ¸…ç†å†…å­˜"""
        self.operation_count += 1
        if self.operation_count >= self.cleanup_threshold:
            import gc
            gc.collect()
            self.operation_count = 0
            logging.debug("[ğŸ§¹] å†…å­˜è‡ªåŠ¨æ¸…ç†å®Œæˆ")

# åˆå§‹åŒ–çˆ¬è™«æ§åˆ¶å™¨
crawler_controller = AdaptiveCrawler()

# åˆå§‹åŒ–å†…å­˜ä¼˜åŒ–å™¨
memory_optimizer = MemoryOptimizer()

# ğŸ”„ å¼¹æ€§æ‰§è¡Œï¼Œè‡ªåŠ¨æ¢å¤
def resilient_execute(func, fallback_func=None, max_attempts=3):
    """å¼¹æ€§æ‰§è¡Œï¼Œè‡ªåŠ¨æ¢å¤"""
    for attempt in range(max_attempts):
        try:
            return func()
        except Exception as e:
            logging.warning(f"[ğŸ”„] ç¬¬{attempt+1}æ¬¡æ‰§è¡Œå¤±è´¥: {e}")
            if attempt == max_attempts - 1 and fallback_func:
                logging.info("[ğŸ†˜] å¯ç”¨å¤‡ç”¨æ–¹æ¡ˆ")
                return fallback_func()
            time.sleep(2 ** attempt)  # æŒ‡æ•°é€€é¿
    return None

def safe_file_operations(file_path, operation="write", content=None):
    """å®‰å…¨çš„æ–‡ä»¶æ“ä½œï¼Œé˜²æ­¢æ•°æ®ä¸¢å¤±"""
    temp_path = file_path + ".tmp"
    
    try:
        if operation == "write" and content is not None:
            # å…ˆå†™å…¥ä¸´æ—¶æ–‡ä»¶
            with open(temp_path, "w", encoding="utf-8") as f:
                f.write(content)
            # ç„¶ååŸå­æ€§åœ°é‡å‘½å
            if os.path.exists(file_path):
                os.remove(file_path)
            os.rename(temp_path, file_path)
            return True
            
        elif operation == "read":
            if os.path.exists(file_path):
                with open(file_path, "r", encoding="utf-8") as f:
                    return f.read()
            return None
            
    except Exception as e:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if os.path.exists(temp_path):
            os.remove(temp_path)
        logging.error(f"[âŒ] æ–‡ä»¶æ“ä½œå¤±è´¥: {e}")
        return None
    
    return None




def get_v2rayn_path() -> str:
    """è·å–v2rayNå¯æ‰§è¡Œæ–‡ä»¶å®Œæ•´è·¯å¾„

    è¿”å›:
        str: v2rayN.exe çš„å®Œæ•´è·¯å¾„
    """
    return os.path.join(Config.BASE_DIR, Config.V2RAYN_EXE)  # æ‹¼æ¥å®Œæ•´è·¯å¾„

# å¼‚æ­¥ä¸‹è½½èŠ‚ç‚¹æ–‡ä»¶
async def download_nodes_file_async(node_url):
    """å¼‚æ­¥ä¸‹è½½èŠ‚ç‚¹æ–‡ä»¶
    
    å‚æ•°:
        node_url: èŠ‚ç‚¹æ–‡ä»¶URL
    
    è¿”å›:
        èŠ‚ç‚¹å†…å®¹æˆ–None
    """
    fake_logging()  # ç”Ÿæˆè¿·æƒ‘æ€§æ—¥å¿—
    logging.info(f"[ğŸ”’] æ­£åœ¨å¼‚æ­¥ä¸‹è½½èŠ‚ç‚¹æ–‡ä»¶: {node_url}")
    
    if has_async:
        async with aiohttp.ClientSession() as session:
            content = await fetch_page_async(session, node_url)
            if content:
                # å»é‡å¤„ç†ä¿æŒä¸å˜
                lines = content.strip().split('\n')
                unique_lines = []
                seen_node_identifiers = set()
                
                for line in lines:
                    if not line.strip():
                        continue
                        
                    node_identifier = None
                    # èŠ‚ç‚¹è§£æé€»è¾‘ä¿æŒä¸å˜
                    if line.startswith("vmess://"):
                        try:
                            vmess_content = line[8:]
                            padding = len(vmess_content) % 4
                            if padding:
                                vmess_content += '=' * (4 - padding)
                            vmess_json = json.loads(base64.b64decode(vmess_content).decode('utf-8', errors='ignore'))
                            address = vmess_json.get("add", "")
                            port = str(vmess_json.get("port", ""))
                            if address and port:
                                node_identifier = f"{address}:{port}"
                        except Exception:
                            pass
                    # å…¶ä»–èŠ‚ç‚¹ç±»å‹çš„å¤„ç†é€»è¾‘ä¿æŒä¸å˜
                    
                    if node_identifier and node_identifier not in seen_node_identifiers:
                        seen_node_identifiers.add(node_identifier)
                        unique_lines.append(line)
                    elif not node_identifier and line not in unique_lines:
                        unique_lines.append(line)
                
                unique_content = '\n'.join(unique_lines)
                return unique_content
    return None


def get_config_path(v2rayn_dir: Optional[str] = None) -> Optional[str]:
    """è·å–v2rayNé…ç½®æ–‡ä»¶å®Œæ•´è·¯å¾„
    
    å‚æ•°:
        v2rayn_dir (str): v2rayNå®‰è£…ç›®å½•ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤ç›®å½•
    
    è¿”å›:
        str: config.jsonçš„å®Œæ•´è·¯å¾„
    """
    # å¦‚æœæä¾›äº†v2rayn_dirï¼Œä½¿ç”¨å®ƒæ¥æŸ¥æ‰¾é…ç½®æ–‡ä»¶
    if v2rayn_dir:
        possible_locations = [
            os.path.join(v2rayn_dir, 'config.json'),
            os.path.join(v2rayn_dir, 'bin', 'config.json'),
            os.path.join(v2rayn_dir, 'data', 'config.json'),
            os.path.join(os.path.expanduser('~'), 'AppData', 'Roaming', 'v2rayN', 'config.json')
        ]

        for path in possible_locations:
            if os.path.exists(path):
                return path
    
    # é»˜è®¤è¿”å›è„šæœ¬ç›®å½•ä¸‹çš„é…ç½®æ–‡ä»¶
    return os.path.join(Config.BASE_DIR, Config.CONFIG_FILE)


def get_nodes_path() -> str:
    """è·å–èŠ‚ç‚¹ä¿¡æ¯æ–‡ä»¶ä¿å­˜è·¯å¾„

    è¿”å›:
        str: nodes.txtçš„å®Œæ•´è·¯å¾„
    """
    return os.path.join(Config.BASE_DIR, Config.NODES_FILE)


# === v2rayN è¿›ç¨‹æ“ä½œ ===
def is_v2rayn_running() -> bool:
    """æ£€æŸ¥v2rayNè¿›ç¨‹æ˜¯å¦æ­£åœ¨è¿è¡Œ

    è¿”å›:
        bool: Trueè¡¨ç¤ºæ­£åœ¨è¿è¡Œï¼ŒFalseè¡¨ç¤ºæœªè¿è¡Œ
    """
    fake_logging()  # ç”Ÿæˆè¿·æƒ‘æ€§æ—¥å¿—
    # éå†æ‰€æœ‰è¿›ç¨‹
    for proc in psutil.process_iter(['name']):
        try:
            # æ£€æŸ¥è¿›ç¨‹åæ˜¯å¦åŒ…å«v2rayn.exe(ä¸åŒºåˆ†å¤§å°å†™)
            if proc.info['name'] and 'v2rayn.exe' in proc.info['name'].lower():
                return True
        except (psutil.NoSuchProcess, psutil.AccessDenied):
            # å¤„ç†è¿›ç¨‹è®¿é—®æƒé™é—®é¢˜
            pass
    return False


def wait_for_v2rayn(timeout: int = Config.CHECK_TIMEOUT) -> bool:
    """ç­‰å¾…v2rayNå¯åŠ¨ï¼Œç›´åˆ°è¶…æ—¶

    å‚æ•°:
        timeout (int): ç­‰å¾…è¶…æ—¶æ—¶é—´(ç§’)

    è¿”å›:
        bool: Trueè¡¨ç¤ºå¯åŠ¨æˆåŠŸï¼ŒFalseè¡¨ç¤ºè¶…æ—¶
    """
    fake_logging()  # ç”Ÿæˆè¿·æƒ‘æ€§æ—¥å¿—
    logging.info(f"[âŒ›] ç­‰å¾…v2rayNå¯åŠ¨ï¼ˆæœ€å¤š {timeout} ç§’ï¼‰...")
    start_time = time.time()  # è®°å½•å¼€å§‹æ—¶é—´

    # åœ¨è¶…æ—¶æ—¶é—´å†…å¾ªç¯æ£€æŸ¥ï¼Œä½¿ç”¨éšæœºé—´éš”å¢åŠ éšè”½æ€§
    while time.time() - start_time < timeout:
        if is_v2rayn_running():  # æ£€æŸ¥è¿›ç¨‹
            logging.info("[âœ…] v2rayN å·²å¯åŠ¨")
            return True
        # éšæœºé—´éš”æ£€æŸ¥ï¼Œé¿å…è§„å¾‹æ€§
        sleep_time = random.uniform(0.8, 1.2)
        time.sleep(sleep_time)

    logging.warning("[âŒ] è¶…æ—¶æœªæ£€æµ‹åˆ° v2rayN è¿›ç¨‹")
    return False


def terminate_v2rayn() -> bool:
    """ç»ˆæ­¢æ­£åœ¨è¿è¡Œçš„v2rayNè¿›ç¨‹

    è¿”å›:
        bool: Trueè¡¨ç¤ºæˆåŠŸç»ˆæ­¢ï¼ŒFalseè¡¨ç¤ºç»ˆæ­¢å¤±è´¥
    """
    fake_logging()  # ç”Ÿæˆè¿·æƒ‘æ€§æ—¥å¿—
    logging.info("[ğŸ”ª] å°è¯•å…³é—­æ—§çš„ v2rayN...")
    terminated = False  # ç»ˆæ­¢çŠ¶æ€æ ‡å¿—

    # éå†æ‰€æœ‰è¿›ç¨‹
    for proc in psutil.process_iter(['name']):
        try:
            if proc.info['name'] and 'v2rayn.exe' in proc.info['name'].lower():
                try:
                    proc.terminate()  # å°è¯•æ­£å¸¸ç»ˆæ­¢
                    proc.wait(timeout=5)  # ç­‰å¾…è¿›ç¨‹ç»“æŸ
                    terminated = True
                except psutil.TimeoutExpired:  # è¶…æ—¶æœªç»“æŸ
                    logging.warning("[âš¡] è¿›ç¨‹è¶…æ—¶ï¼Œå¼ºåˆ¶ç»ˆæ­¢")
                    proc.kill()  # å¼ºåˆ¶ç»ˆæ­¢
                    terminated = True
                except psutil.NoSuchProcess:  # è¿›ç¨‹å·²ä¸å­˜åœ¨
                    pass
                except psutil.AccessDenied:
                    logging.error("[ğŸš«] æ²¡æœ‰è¶³å¤Ÿæƒé™ç»ˆæ­¢è¿›ç¨‹")
        except (psutil.NoSuchProcess, psutil.AccessDenied):
            pass

    # ç­‰å¾…è¿›ç¨‹å®Œå…¨é€€å‡ºï¼Œä½¿ç”¨éšæœºå»¶æ—¶
    time.sleep(random.uniform(0.5, 1.5))  # éšæœºç­‰å¾…ï¼Œå¢åŠ éšè”½æ€§
    return terminated


def start_v2rayn() -> bool:
    """å¯åŠ¨v2rayNç¨‹åºï¼ˆä½¿ç”¨éšèº«æ¨¡å¼ï¼‰

    è¿”å›:
        bool: Trueè¡¨ç¤ºå¯åŠ¨æˆåŠŸï¼ŒFalseè¡¨ç¤ºå¯åŠ¨å¤±è´¥
    """
    v2rayn_path = get_v2rayn_path()  # è·å–å®Œæ•´è·¯å¾„

    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(v2rayn_path):
        logging.error(f"[âŒ] v2rayN æ–‡ä»¶ä¸å­˜åœ¨: {v2rayn_path}")
        return False

    try:
        fake_logging()  # ç”Ÿæˆè¿·æƒ‘æ€§æ—¥å¿—
        logging.info("[ğŸš€] æ­£åœ¨å¯åŠ¨ v2rayN (éšèº«æ¨¡å¼)...")
        
        # ä½¿ç”¨éšèº«è¿›ç¨‹å¯åŠ¨ç¨‹åº
        if Config.ENABLE_STEALTH and has_win32:
            create_ghost_process([v2rayn_path])
        else:
            # åå¤‡æ–¹æ¡ˆ
            startupinfo = subprocess.STARTUPINFO()
            startupinfo.dwFlags |= subprocess.STARTF_USESHOWWINDOW
            subprocess.Popen([v2rayn_path], startupinfo=startupinfo)
            
        # æ¨¡æ‹Ÿäººç±»æ“ä½œï¼Œç­‰å¾…ä¸€å°æ®µéšæœºæ—¶é—´å†æ£€æŸ¥
        time.sleep(random.uniform(0.5, 1.5))
        return wait_for_v2rayn()  # ç­‰å¾…å¯åŠ¨å®Œæˆ
    except Exception as e:
        logging.error(f"[âŒ] å¯åŠ¨ v2rayN å¤±è´¥: {e}")
        return False


def restart_v2rayn() -> bool:
    """é‡å¯v2rayNç¨‹åº

    è¿”å›:
        bool: Trueè¡¨ç¤ºé‡å¯æˆåŠŸï¼ŒFalseè¡¨ç¤ºå¤±è´¥
    """
    terminate_v2rayn()  # å…ˆç»ˆæ­¢
    return start_v2rayn()  # å†å¯åŠ¨


# === è®¢é˜…ç®¡ç† ===
@smart_retry(max_retries=3)
def update_v2rayn_subscription(new_url: str) -> bool:
    """
    æ›¿æ¢ v2rayN config.json çš„è®¢é˜…é“¾æ¥ä¸ºæ–°çš„ URLï¼Œæ¸…é™¤æ‰€æœ‰æ—§è®¢é˜…ã€‚
    é»‘å®¢æ¨¡å¼ï¼šæ™ºèƒ½é‡è¯•ã€éšè”½æ“ä½œã€æ··æ·†é…ç½®
    """
    fake_logging()  # ç”Ÿæˆè¿·æƒ‘æ€§æ—¥å¿—
    config_path = get_config_path()
    if not os.path.exists(config_path):
        logging.error(f"[âŒ] æ‰¾ä¸åˆ° config.jsonï¼š{config_path}")
        return False

    try:
        # è¯»å–é…ç½®æ–‡ä»¶å‰æ·»åŠ éšæœºå»¶è¿Ÿ
        time.sleep(random.uniform(0.1, 0.3))
        with open(config_path, "r", encoding="utf-8") as f:
            config_data = json.load(f)

        # æ·»åŠ æ··æ·†é…ç½®ï¼Œæé«˜éšè”½æ€§
        if Config.ENABLE_STEALTH:
            # æ·»åŠ ä¸€äº›çœ‹ä¼¼æ­£å¸¸ä½†å®é™…ä¸Šæ— æ„ä¹‰çš„é…ç½®é¡¹
            config_data["lastUpdateTime"] = int(time.time() * 1000)
            config_data["autoUpdateCore"] = False
            config_data["logLevel"] = "none"  # é™ä½æ—¥å¿—çº§åˆ«
            config_data["guiType"] = 0

        # è¦†ç›–æ—§çš„ subscriptionsï¼Œä½¿ç”¨éšæœºè®¢é˜…åç§°
        subscription_remarks = "Auto Imported" if not Config.ENABLE_STEALTH else generate_random_string(8)
        config_data["subscriptions"] = [{"url": new_url, "enabled": True, "remarks": subscription_remarks}]

        # å†™å…¥å‰çš„éšæœºå»¶è¿Ÿ
        time.sleep(random.uniform(0.1, 0.3))
        with open(config_path, "w", encoding="utf-8") as f:
            json.dump(config_data, f, indent=4, ensure_ascii=False)

        # ä¸ç›´æ¥è®°å½•å®Œæ•´URLï¼Œå¢åŠ å®‰å…¨æ€§
        masked_url = new_url[:10] + "..." + new_url[-10:] if len(new_url) > 20 else new_url
        logging.info(f"[âœ…] æˆåŠŸæ›¿æ¢è®¢é˜…é“¾æ¥: {masked_url}")
        return True

    except Exception as e:
        logging.error(f"[âŒ] æ›´æ–°è®¢é˜…å¤±è´¥: {type(e).__name__}: {e}")
        raise  # æŠ›å‡ºå¼‚å¸¸ï¼Œè®©æ™ºèƒ½é‡è¯•è£…é¥°å™¨å¤„ç†


def add_nodes_to_mibei_group() -> bool:
    """
    åœ¨v2rayNä¸­åˆ›å»ºåä¸º"ç±³è´"çš„åˆ†ç»„ï¼Œå¹¶å°†èŠ‚ç‚¹ç²˜è´´åˆ°è¯¥åˆ†ç»„ä¸­ã€‚
    å¦‚æœåˆ†ç»„å·²å­˜åœ¨ï¼Œåˆ™è¦†ç›–åŸæœ‰èŠ‚ç‚¹ã€‚
    é»‘å®¢æ¨¡å¼ï¼šæ™ºèƒ½èŠ‚ç‚¹ç­›é€‰ã€éšæœºåŒ–ã€éšè”½æ€§å¢å¼º
    """
    fake_logging()  # ç”Ÿæˆè¿·æƒ‘æ€§æ—¥å¿—
    # è·å–é…ç½®æ–‡ä»¶è·¯å¾„
    v2rayn_dir = find_v2rayn_installation()
    if not v2rayn_dir:
        logging.error("[âŒ] æ‰¾ä¸åˆ°v2rayNå®‰è£…ç›®å½•")
        return False
    
    config_path = get_config_path(v2rayn_dir)
    if not config_path:
        logging.error("[âŒ] æ‰¾ä¸åˆ°config.jsonæ–‡ä»¶")
        return False
    
    # è·å–èŠ‚ç‚¹æ–‡ä»¶è·¯å¾„
    nodes_path = get_nodes_path()
    if not os.path.exists(nodes_path):
        logging.error(f"[âŒ] æ‰¾ä¸åˆ°èŠ‚ç‚¹æ–‡ä»¶: {nodes_path}")
        return False
    
    try:
        # è¯»å–é…ç½®æ–‡ä»¶
        with open(config_path, "r", encoding="utf-8") as f:
            config_data = json.load(f)
        
        # è¯»å–èŠ‚ç‚¹æ–‡ä»¶å†…å®¹
        with open(nodes_path, "r", encoding="utf-8") as f:
            node_lines = f.readlines()
        
        # æ™ºèƒ½èŠ‚ç‚¹ç­›é€‰
        if Config.ENABLE_NODE_FILTERING:
            logging.info("[ğŸ§ ] æ­£åœ¨ç­›é€‰é«˜è´¨é‡èŠ‚ç‚¹...")
            # åªä¿ç•™ä¸€å®šæ•°é‡çš„èŠ‚ç‚¹ï¼Œé¿å…è¿‡äºè‡ƒè‚¿
            if len(node_lines) > Config.MAX_NODES:
                # éšæœºé€‰æ‹©ä¸€éƒ¨åˆ†èŠ‚ç‚¹ï¼Œé¿å…è§„å¾‹æ€§
                node_lines = random.sample(node_lines, Config.MAX_NODES)
            logging.info(f"[âœ…] å·²ç­›é€‰å‡º {len(node_lines)} ä¸ªèŠ‚ç‚¹")
        
        # ç¡®ä¿serverså­—æ®µå­˜åœ¨
        if "servers" not in config_data:
            config_data["servers"] = []
        
        # ä½¿ç”¨éšæœºåŒ–åˆ†ç»„åå¢åŠ éšè”½æ€§
        group_name = "ç±³è´" if not Config.ENABLE_STEALTH else f"ç±³è´_{generate_random_string(4)}"
        
        # è¿‡æ»¤æ‰æ—§èŠ‚ç‚¹
        old_nodes = [server for server in config_data["servers"] if server.get("group") == "ç±³è´"]
        config_data["servers"] = [server for server in config_data["servers"] if server.get("group") != "ç±³è´"]
        
        # è®°å½•æ—§èŠ‚ç‚¹æ•°é‡
        logging.info(f"[ğŸ§¹] å·²æ¸…é™¤ {len(old_nodes)} ä¸ªæ—§èŠ‚ç‚¹")
        
        # ä¸ºæ¯ä¸ªèŠ‚ç‚¹æ·»åŠ åˆ°ç±³è´åˆ†ç»„ï¼Œä½¿ç”¨æ··æ·†ç­–ç•¥
        new_server_count = 0
        for line in node_lines:
            line = line.strip()
            if not line:
                continue
                
            # æ·»åŠ éšæœºå»¶æ—¶ï¼Œæ¨¡æ‹Ÿäººå·¥æ“ä½œ
            time.sleep(random.uniform(0.01, 0.05))
            
            # æ ¹æ®ä¸åŒçš„èŠ‚ç‚¹ç±»å‹è§£æ
            try:
                if line.startswith("vmess://"):
                    # å¤„ç†vmessèŠ‚ç‚¹
                    vmess_content = line[8:]
                    # å¤„ç†å¯èƒ½çš„base64å¡«å……é—®é¢˜
                    padding = len(vmess_content) % 4
                    if padding:
                        vmess_content += '=' * (4 - padding)
                    
                    vmess_json = json.loads(base64.b64decode(vmess_content).decode('utf-8'))
                    
                    # åˆ›å»ºæ–°çš„æœåŠ¡å™¨æ¡ç›®
                    server = {
                        "id": str(random.randint(100000, 999999)),
                        "remarks": vmess_json.get("ps", f"èŠ‚ç‚¹_{generate_random_string(6)}"),
                        "group": group_name,
                        "type": "VMess",
                        "address": vmess_json.get("add", ""),
                        "port": int(vmess_json.get("port", 443)),
                        "uuid": vmess_json.get("id", ""),
                        "alterId": int(vmess_json.get("aid", 0)),
                        "security": vmess_json.get("scy", "auto"),
                        "network": vmess_json.get("net", "tcp"),
                        "headerType": vmess_json.get("type", "none"),
                        "requestHost": vmess_json.get("host", ""),
                        "path": vmess_json.get("path", ""),
                        "streamSecurity": vmess_json.get("tls", ""),
                        "sni": vmess_json.get("sni", ""),
                        "fingerprint": vmess_json.get("fp", ""),
                        "allowInsecure": True
                    }
                    
                    # å¦‚æœå¼€å¯æ™ºèƒ½æµ‹é€Ÿï¼Œæµ‹è¯•èŠ‚ç‚¹å»¶è¿Ÿ
                    if Config.ENABLE_SPEED_TEST and vmess_json.get("add") and vmess_json.get("port"):
                        latency = test_latency(vmess_json.get("add"), int(vmess_json.get("port", 443)))
                        if latency < Config.MAX_LATENCY or Config.IGNORE_LATENCY_TEST:
                            config_data["servers"].append(server)
                            new_server_count += 1
                            if latency < float('inf'):
                                logging.debug(f"[ğŸš€] æ·»åŠ é«˜é€ŸèŠ‚ç‚¹: {latency:.2f}ms")
                    else:
                        config_data["servers"].append(server)
                        new_server_count += 1
                
                elif line.startswith("trojan://"):
                    # å¤„ç†trojanèŠ‚ç‚¹ï¼ˆç®€åŒ–ç‰ˆï¼‰
                    server = {
                        "id": str(random.randint(100000, 999999)),
                        "remarks": f"Trojan_{generate_random_string(6)}",
                        "group": group_name,
                        "type": "Trojan",
                        "allowInsecure": True
                    }
                    config_data["servers"].append(server)
                    new_server_count += 1
                    
                elif line.startswith("ss://"):
                    # å¤„ç†shadowsocksèŠ‚ç‚¹ï¼ˆç®€åŒ–ç‰ˆï¼‰
                    server = {
                        "id": str(random.randint(100000, 999999)),
                        "remarks": f"SS_{generate_random_string(6)}",
                        "group": group_name,
                        "type": "Shadowsocks",
                    }
                    config_data["servers"].append(server)
                    new_server_count += 1
            except Exception as e:
                logging.warning(f"[âš ï¸] è§£æèŠ‚ç‚¹å¤±è´¥: {line[:30]}... {str(e)}")
                continue
        
        # ä¿å­˜å‰éšæœºå»¶è¿Ÿ
        time.sleep(random.uniform(0.2, 0.5))
        
        # ä¿å­˜æ›´æ–°åçš„é…ç½®æ–‡ä»¶
        with open(config_path, "w", encoding="utf-8") as f:
            json.dump(config_data, f, indent=4, ensure_ascii=False)
        
        logging.info(f"[âœ…] æˆåŠŸå°†{new_server_count}ä¸ªèŠ‚ç‚¹æ·»åŠ åˆ° {group_name} åˆ†ç»„")
        return True
        
    except json.JSONDecodeError as e:
        logging.error(f"[âŒ] è§£æé…ç½®æ–‡ä»¶å¤±è´¥: {str(e)}")
        return False
    except Exception as e:
        logging.error(f"[âŒ] æ·»åŠ èŠ‚ç‚¹åˆ°ç±³è´åˆ†ç»„å¤±è´¥: {type(e).__name__}: {e}")
        return False


def test_latency(host: str, port: int = 443, timeout: float = 1.0) -> float:
    """TCP pingæµ‹è¯•ï¼Œè¿”å›æ¯«ç§’å»¶è¿Ÿï¼ˆé»‘å®¢æ¨¡å¼ï¼‰"""
    try:
        # æ¨¡æ‹Ÿæ›´çœŸå®çš„ç½‘ç»œè¡Œä¸ºï¼Œæ·»åŠ éšæœºå¾®å°å»¶è¿Ÿ
        time.sleep(random.uniform(0.001, 0.005))
        start = time.time()
        sock = socket.create_connection((host, port), timeout)
        sock.close()
        latency = (time.time() - start) * 1000
        logging.debug(f"[ğŸ“Š] èŠ‚ç‚¹å»¶è¿Ÿ: {host}:{port} = {latency:.2f}ms")
        return latency
    except socket.timeout:
        logging.debug(f"[â°] èŠ‚ç‚¹è¶…æ—¶: {host}:{port}")
        return float("inf")
    except Exception as e:
        logging.debug(f"[âŒ] å»¶è¿Ÿæµ‹è¯•å¤±è´¥: {host}:{port} - {str(e)}")
        return float("inf")

# å¼‚æ­¥ç‰ˆæœ¬çš„å»¶è¿Ÿæµ‹è¯•
async def test_latency_async(host: str, port: int = 443, timeout: float = 1.0) -> float:
    """å¼‚æ­¥TCP pingæµ‹è¯•ï¼Œè¿”å›æ¯«ç§’å»¶è¿Ÿ"""
    if not has_async:
        # å¦‚æœå¼‚æ­¥æ¨¡å—ä¸å¯ç”¨ï¼Œå›é€€åˆ°åŒæ­¥ç‰ˆæœ¬
        return test_latency(host, port, timeout)
        
    try:
        # æ¨¡æ‹Ÿæ›´çœŸå®çš„ç½‘ç»œè¡Œä¸ºï¼Œæ·»åŠ éšæœºå¾®å°å»¶è¿Ÿ
        await asyncio.sleep(random.uniform(0.001, 0.005))
        start = time.time()
        # ä½¿ç”¨å¼‚æ­¥æ–¹å¼åˆ›å»ºsocketè¿æ¥
        reader, writer = await asyncio.wait_for(
            asyncio.open_connection(host, port),
            timeout=timeout
        )
        writer.close()
        await writer.wait_closed()
        latency = (time.time() - start) * 1000
        logging.debug(f"[âš¡] å¼‚æ­¥èŠ‚ç‚¹å»¶è¿Ÿ: {host}:{port} = {latency:.2f}ms")
        return latency
    except Exception:
        return float("inf")

# æ™ºèƒ½èŠ‚ç‚¹æµ‹é€Ÿå‡½æ•°
async def benchmark_nodes_async(nodes):
    """å¹¶å‘æµ‹é€Ÿæ‰€æœ‰èŠ‚ç‚¹ï¼Œåªä¿ç•™æœ€å¿«çš„èŠ‚ç‚¹"""
    if not has_async:
        # å¦‚æœå¼‚æ­¥ä¸å¯ç”¨ï¼Œå›é€€åˆ°ç®€å•ç­›é€‰
        return nodes[:min(len(nodes), Config.MAX_NODES)]
        
    # æ„å»ºæµ‹é€Ÿä»»åŠ¡
    tasks = []
    for i, node in enumerate(nodes):
        # è§£æèŠ‚ç‚¹ä¿¡æ¯ï¼Œæå–åœ°å€å’Œç«¯å£
        if node.startswith("vmess://"):
            try:
                vmess_content = node[8:]
                padding = len(vmess_content) % 4
                if padding:
                    vmess_content += '=' * (4 - padding)
                vmess_json = json.loads(base64.b64decode(vmess_content).decode('utf-8', errors='ignore'))
                host = vmess_json.get("add", "")
                port = int(vmess_json.get("port", 443))
                if host and port:
                    task = asyncio.create_task(test_latency_async(host, port))
                    tasks.append((task, node, i))
            except Exception:
                pass
    
    # å¹¶å‘æ‰§è¡Œæ‰€æœ‰æµ‹é€Ÿä»»åŠ¡
    results = []
    for task, node, index in tasks:
        try:
            latency = await task
            if latency < Config.MAX_LATENCY:
                results.append((latency, node, index))
        except Exception:
            pass
    
    # æŒ‰å»¶è¿Ÿæ’åºï¼Œå–æœ€å¿«çš„èŠ‚ç‚¹
    results.sort(key=lambda x: x[0])
    # å–å‰N%çš„èŠ‚ç‚¹æˆ–å›ºå®šæ•°é‡
    top_count = min(len(results), Config.MAX_NODES)
    top_nodes = [node for _, node, _ in results[:top_count]]
    
    logging.info(f"[ğŸ¯] å·²ä»{len(nodes)}ä¸ªèŠ‚ç‚¹ä¸­ç­›é€‰å‡º{len(top_nodes)}ä¸ªä½å»¶è¿ŸèŠ‚ç‚¹")
    return top_nodes


# === èŠ‚ç‚¹è·å–åŠŸèƒ½ ===
def get_today_date_str() -> str:
    """è·å–å½“å‰æ—¥æœŸçš„æ ¼å¼åŒ–å­—ç¬¦ä¸²

    è¿”å›:
        str: æ ¼å¼ä¸º"YYYYå¹´MMæœˆDDæ—¥"çš„æ—¥æœŸå­—ç¬¦ä¸²
    """
    return datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥')


def find_node_page_url(main_url: str) -> Optional[str]:
    """ä»ä¸»é¡µæŸ¥æ‰¾åŒ…å«å½“å¤©èŠ‚ç‚¹çš„é¡µé¢URL

    å‚æ•°:
        main_url (str): ç½‘ç«™ä¸»é¡µURL

    è¿”å›:
        Optional[str]: æ‰¾åˆ°çš„URLï¼Œæœªæ‰¾åˆ°åˆ™è¿”å›None
    """
    try:
        logging.info(f"æ­£åœ¨è®¿é—®ä¸»é¡µé¢: {main_url}")
        # å‘é€HTTP GETè¯·æ±‚
        response = requests.get(main_url, headers=get_random_headers(), timeout=5)
        response.raise_for_status()  # æ£€æŸ¥è¯·æ±‚æ˜¯å¦æˆåŠŸ

        # è§£æHTMLå†…å®¹
        soup = BeautifulSoup(response.text, 'html.parser')
        today = get_today_date_str()  # è·å–å½“å¤©æ—¥æœŸå­—ç¬¦ä¸²

        # æŸ¥æ‰¾æ‰€æœ‰<a>æ ‡ç­¾
        for a_tag in soup.find_all('a', href=True):
            link_text = a_tag.get_text(strip=True)  # è·å–é“¾æ¥æ–‡æœ¬
            # æ£€æŸ¥æ˜¯å¦ç¬¦åˆå½“å¤©èŠ‚ç‚¹é“¾æ¥ç‰¹å¾
            if link_text.startswith(today) and "å…è´¹ç²¾é€‰èŠ‚ç‚¹" in link_text:
                return a_tag['href']  # è¿”å›æ‰¾åˆ°çš„URL

        logging.warning("æœªæ‰¾åˆ°ä»Šæ—¥å…è´¹ç²¾é€‰èŠ‚ç‚¹é“¾æ¥")
    except requests.RequestException as e:
        logging.error(f"è®¿é—®ä¸»é¡µé¢å¤±è´¥: {e}")
    except Exception as e:
        logging.error(f"è§£æä¸»é¡µé¢å¤±è´¥: {e}")

    return None


def find_v2rayn_installation(base_dir: str = None) -> Optional[str]:
    """
    åœ¨ç³»ç»Ÿä¸ŠæŸ¥æ‰¾ v2rayN çš„å®‰è£…ç›®å½•
    æœç´¢é¡ºåºï¼š
    1. è„šæœ¬æ‰€åœ¨ç›®å½•
    2. ç¨‹åºæ–‡ä»¶é»˜è®¤å®‰è£…ç›®å½•
    3. æ•´ä¸ªç³»ç»Ÿæœç´¢ï¼ˆé™åˆ¶æ·±åº¦ï¼‰
    """
    # å¯èƒ½çš„é»˜è®¤å®‰è£…è·¯å¾„
    default_paths = [
        os.path.join(os.environ.get('ProgramFiles', ''), 'v2rayN'),
        os.path.join(os.environ.get('ProgramFiles(x86)', ''), 'v2rayN'),
        os.path.expanduser('~\\AppData\\Local\\Programs\\v2rayN')
    ]

    # è¦æ£€æŸ¥çš„ç›®å½•åˆ—è¡¨
    search_paths = []
    if base_dir:
        search_paths.append(base_dir)
    search_paths.extend(default_paths)

    # æ£€æŸ¥è¿™äº›è·¯å¾„
    for path in search_paths:
        exe_path = os.path.join(path, 'v2rayN.exe')
        if os.path.exists(exe_path):
            return path

    # å¦‚æœè¿˜æ²¡æ‰¾åˆ°ï¼Œå°è¯•åœ¨æ•´ä¸ªç³»ç»Ÿä¸­æœç´¢ï¼ˆé™åˆ¶æ·±åº¦ï¼‰
    for root, dirs, files in os.walk('d:\\', topdown=True):
        if 'v2rayN.exe' in files:
            return root
        # é™åˆ¶æœç´¢æ·±åº¦ä¸º3å±‚
        if root.count(os.sep) >= 3:
            dirs[:] = []  # ä¸å†é€’å½’æ›´æ·±å±‚

    return None


def validate_v2rayn_installation() -> bool:
    """éªŒè¯v2rayNå®‰è£…æ˜¯å¦æ­£ç¡®"""
    # 1. é¦–å…ˆå°è¯•è„šæœ¬æ‰€åœ¨ç›®å½•
    script_dir = os.path.dirname(os.path.abspath(__file__))
    v2rayn_dir = find_v2rayn_installation(script_dir)

    if not v2rayn_dir:
        print("é”™è¯¯: æ‰¾ä¸åˆ° v2rayN å®‰è£…ç›®å½•")
        return False

    print(f"æ‰¾åˆ° v2rayN ç›®å½•: {v2rayn_dir}")

    # 2. æŸ¥æ‰¾é…ç½®æ–‡ä»¶
    config_path = get_config_path(v2rayn_dir)
    if not config_path:
        print("é”™è¯¯: æ‰¾ä¸åˆ° config.json æ–‡ä»¶")
        return False

    print(f"æ‰¾åˆ°é…ç½®æ–‡ä»¶: {config_path}")

    # 3. éªŒè¯xray.exe  æ˜¯å¦å­˜åœ¨
    exe_path = os.path.join(v2rayn_dir, 'v2rayN.exe')
    if not os.path.exists(exe_path):
        print("é”™è¯¯: æ‰¾ä¸åˆ°xray.exe ")
        return False

    print("æ‰€æœ‰å¿…è¦æ–‡ä»¶éªŒè¯é€šè¿‡")
    print(f"v2rayN.exe è·¯å¾„: {exe_path}")
    print(f"config.json è·¯å¾„: {config_path}")
    return True


def extract_node_url(node_page_url: str) -> Optional[str]:
    """ä»èŠ‚ç‚¹é¡µé¢æå–èŠ‚ç‚¹æ–‡ä»¶URL

    å‚æ•°:
        node_page_url (str): èŠ‚ç‚¹é¡µé¢URL

    è¿”å›:
        Optional[str]: æ‰¾åˆ°çš„èŠ‚ç‚¹æ–‡ä»¶URLï¼Œæœªæ‰¾åˆ°åˆ™è¿”å›None
    """
    try:
        logging.info(f"æ­£åœ¨è®¿é—®èŠ‚ç‚¹é¡µé¢: {node_page_url}")
        response = requests.get(node_page_url, headers=get_random_headers(), timeout=5)
        response.raise_for_status()

        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é….txtæ–‡ä»¶é“¾æ¥
        txt_pattern = re.compile(r'http[s]?://mm\.mibei77\.com/(?:\d{6}|\d{4}\.\d{2})/[\w\.]+\.(?:txt|yaml)', re.IGNORECASE)
        txt_links = txt_pattern.findall(response.text)  # æŸ¥æ‰¾æ‰€æœ‰åŒ¹é…çš„URL

        if txt_links:
            return txt_links[0]  # è¿”å›ç¬¬ä¸€ä¸ªåŒ¹é…çš„URL

        logging.warning("æœªæ‰¾åˆ° .txt èŠ‚ç‚¹é“¾æ¥")
    except requests.RequestException as e:
        logging.error(f"è®¿é—®èŠ‚ç‚¹é¡µé¢å¤±è´¥: {e}")
    except Exception as e:
        logging.error(f"è§£æèŠ‚ç‚¹é¡µé¢å¤±è´¥: {e}")

    return None


@smart_retry(max_retries=3)
def download_nodes_file(node_url: str) -> bool:
    """ä¸‹è½½èŠ‚ç‚¹æ–‡ä»¶å¹¶ä¿å­˜åˆ°æœ¬åœ°ï¼ˆé»‘å®¢æ¨¡å¼ï¼‰

    å‚æ•°:
        node_url (str): èŠ‚ç‚¹æ–‡ä»¶URL

    è¿”å›:
        bool: Trueè¡¨ç¤ºä¸‹è½½æˆåŠŸï¼ŒFalseè¡¨ç¤ºå¤±è´¥
    """
    fake_logging()  # ç”Ÿæˆè¿·æƒ‘æ€§æ—¥å¿—
    memory_optimizer.auto_cleanup()  # è‡ªåŠ¨æ¸…ç†å†…å­˜
    try:
        logging.info(f"[ğŸ”’] æ­£åœ¨ä¸‹è½½èŠ‚ç‚¹æ–‡ä»¶: {node_url[:20]}...")
        # ä½¿ç”¨éšèº«æ¨¡å¼è¯·æ±‚å¤´
        headers = get_random_headers(stealth=True)
        
        # éšæœºå»¶æ—¶ï¼Œæ¨¡æ‹Ÿäººç±»æ“ä½œ
        time.sleep(random.uniform(0.5, 1.5))
        
        response = requests.get(node_url, headers=headers, timeout=5)
        response.raise_for_status()  # æ£€æŸ¥ä¸‹è½½æ˜¯å¦æˆåŠŸ
        
        # ç»Ÿè®¡ä¸‹è½½å¤§å°
        content_length = len(response.text)
        logging.info(f"[ğŸ“¥] æˆåŠŸä¸‹è½½èŠ‚ç‚¹æ–‡ä»¶ï¼Œå¤§å°: {content_length / 1024:.2f}KB")

        # å»é‡å¤„ç†
        lines = response.text.strip().split('\n')
        
        # åŠ å¼ºç‰ˆå»é‡ï¼šåŸºäºåœ°å€å’Œç«¯å£çš„åŒé‡åˆ¤æ–­
        unique_lines = []
        seen_node_identifiers = set()  # ç”¨äºå­˜å‚¨å·²è§è¿‡çš„èŠ‚ç‚¹æ ‡è¯†ï¼ˆåœ°å€+ç«¯å£ï¼‰
        
        for line in lines:
            if not line.strip():
                continue
                
            # å°è¯•è§£æèŠ‚ç‚¹ï¼Œæå–åœ°å€å’Œç«¯å£
            node_identifier = None
            
            # å¤„ç†vmessèŠ‚ç‚¹
            if line.startswith("vmess://"):
                try:
                    vmess_content = line[8:]
                    # å¤„ç†å¯èƒ½çš„base64å¡«å……é—®é¢˜
                    padding = len(vmess_content) % 4
                    if padding:
                        vmess_content += '=' * (4 - padding)
                    
                    vmess_json = json.loads(base64.b64decode(vmess_content).decode('utf-8', errors='ignore'))
                    address = vmess_json.get("add", "")
                    port = str(vmess_json.get("port", ""))
                    if address and port:
                        node_identifier = f"{address}:{port}"
                except Exception:
                    pass  # è§£æå¤±è´¥åˆ™å›é€€åˆ°åŸå§‹å»é‡æ–¹å¼
            
            # å¤„ç†trojanèŠ‚ç‚¹ï¼ˆç®€åŒ–è§£æï¼‰
            elif line.startswith("trojan://"):
                try:
                    # å°è¯•ä»URLä¸­æå–åœ°å€å’Œç«¯å£
                    pattern = r'trojan://[^@]+@([^:]+):(\d+)'  # ç®€åŒ–çš„æ­£åˆ™åŒ¹é…
                    match = re.search(pattern, line)
                    if match:
                        address = match.group(1)
                        port = match.group(2)
                        node_identifier = f"{address}:{port}"
                except Exception:
                    pass
            
            # å¤„ç†ssèŠ‚ç‚¹ï¼ˆç®€åŒ–è§£æï¼‰
            elif line.startswith("ss://"):
                try:
                    # å°è¯•ä»URLä¸­æå–åœ°å€å’Œç«¯å£
                    ss_content = line[5:]
                    if '#' in ss_content:
                        ss_content = ss_content.split('#')[0]  # å»é™¤èŠ‚ç‚¹åç§°éƒ¨åˆ†
                    # å¤„ç†å¯èƒ½çš„base64å¡«å……é—®é¢˜
                    padding = len(ss_content) % 4
                    if padding:
                        ss_content += '=' * (4 - padding)
                    
                    decoded = base64.b64decode(ss_content).decode('utf-8', errors='ignore')
                    pattern = r'[^@]+@([^:]+):(\d+)'  # ç®€åŒ–çš„æ­£åˆ™åŒ¹é…
                    match = re.search(pattern, decoded)
                    if match:
                        address = match.group(1)
                        port = match.group(2)
                        node_identifier = f"{address}:{port}"
                except Exception:
                    pass
            
            # å¦‚æœæˆåŠŸæå–äº†èŠ‚ç‚¹æ ‡è¯†ï¼Œä½¿ç”¨å®ƒè¿›è¡Œå»é‡
            if node_identifier and node_identifier not in seen_node_identifiers:
                seen_node_identifiers.add(node_identifier)
                unique_lines.append(line)
            # å¦‚æœæ— æ³•è§£æèŠ‚ç‚¹æ ‡è¯†ï¼Œåˆ™ä½¿ç”¨åŸå§‹è¡Œå†…å®¹è¿›è¡Œå»é‡ï¼ˆå›é€€æ–¹æ¡ˆï¼‰
            elif not node_identifier and line not in unique_lines:
                unique_lines.append(line)
        
        unique_content = '\n'.join(unique_lines)
        
        # æ™ºèƒ½èŠ‚ç‚¹ç­›é€‰
        if Config.ENABLE_NODE_FILTERING and len(unique_lines) > Config.MAX_NODES:
            # å¼‚æ­¥å¹¶å‘æµ‹é€Ÿé€‰æ‹©æœ€ä½³èŠ‚ç‚¹
            if has_async and Config.ENABLE_SPEED_TEST:
                logging.info("[ğŸ§ ] æ­£åœ¨è¿›è¡Œæ™ºèƒ½èŠ‚ç‚¹æµ‹é€Ÿ...")
                # è¿è¡Œå¼‚æ­¥æµ‹é€Ÿä»»åŠ¡
                import asyncio
                unique_lines = asyncio.run(benchmark_nodes_async(unique_lines))
            else:
                # ç®€å•éšæœºç­›é€‰
                unique_lines = random.sample(unique_lines, Config.MAX_NODES)
        
        unique_content = '\n'.join(unique_lines)
        
        # è®°å½•å»é‡æƒ…å†µ
        if len(unique_lines) < len(lines):
            removed_count = len(lines) - len(unique_lines)
            logging.info(f"[ğŸ§¹] èŠ‚ç‚¹å»é‡å®Œæˆï¼Œä»{len(lines)}ä¸ªèŠ‚ç‚¹ä¸­å»é™¤äº†{removed_count}ä¸ªé‡å¤/ä½è´¨é‡èŠ‚ç‚¹")
        
        # è·å–ä¿å­˜è·¯å¾„å¹¶å†™å…¥æ–‡ä»¶
        nodes_path = get_nodes_path()
        
        # å†™å…¥å‰éšæœºå»¶è¿Ÿ
        time.sleep(random.uniform(0.1, 0.3))
        
        with open(nodes_path, "w", encoding="utf-8") as f:
            f.write(unique_content)

        logging.info(f"[âœ…] èŠ‚ç‚¹æ–‡ä»¶å·²ä¿å­˜åˆ°: {nodes_path}ï¼Œå…±{len(unique_lines)}ä¸ªèŠ‚ç‚¹")
        
        # æ›´æ–°çˆ¬è™«æ§åˆ¶å™¨ç»Ÿè®¡ä¿¡æ¯
        crawler_controller.record_success()
        
        return True
    except requests.RequestException as e:
        logging.error(f"[âŒ] ä¸‹è½½èŠ‚ç‚¹æ–‡ä»¶å¤±è´¥: {e}")
        # æ›´æ–°çˆ¬è™«æ§åˆ¶å™¨ç»Ÿè®¡ä¿¡æ¯
        crawler_controller.record_failure()
        raise  # æŠ›å‡ºå¼‚å¸¸è®©æ™ºèƒ½é‡è¯•è£…é¥°å™¨å¤„ç†
    except Exception as e:
        logging.error(f"[âŒ] ä¿å­˜èŠ‚ç‚¹æ–‡ä»¶å¤±è´¥: {e}")
        crawler_controller.record_failure()
        raise

# å¼‚æ­¥ç‰ˆæœ¬çš„ä¸‹è½½å‡½æ•°
async def download_nodes_file_async(node_url: str) -> bool:
    """å¼‚æ­¥ä¸‹è½½èŠ‚ç‚¹æ–‡ä»¶å¹¶ä¿å­˜åˆ°æœ¬åœ°"""
    if not has_async:
        # å›é€€åˆ°åŒæ­¥ç‰ˆæœ¬
        return download_nodes_file(node_url)
    
    fake_logging()
    try:
        logging.info(f"[âš¡] æ­£åœ¨å¼‚æ­¥ä¸‹è½½èŠ‚ç‚¹æ–‡ä»¶: {node_url[:20]}...")
        
        headers = get_random_headers(stealth=True)
        
        async with aiohttp.ClientSession() as session:
            async with session.get(node_url, headers=headers, timeout=5) as response:
                response.raise_for_status()
                content = await response.text()
        
        # å¤„ç†é€»è¾‘ä¸åŒæ­¥ç‰ˆæœ¬ç±»ä¼¼
        lines = content.strip().split('\n')
        
        # å»é‡å’Œç­›é€‰é€»è¾‘...
        unique_lines = []
        seen_node_identifiers = set()
        
        for line in lines:
            if not line.strip():
                continue
            # ç®€åŒ–ç‰ˆæœ¬çš„å»é‡é€»è¾‘
            if line not in unique_lines:
                unique_lines.append(line)
        
        # å¹¶å‘æµ‹é€Ÿé€‰æ‹©æœ€ä½³èŠ‚ç‚¹
        if Config.ENABLE_NODE_FILTERING and has_async:
            unique_lines = await benchmark_nodes_async(unique_lines)
        
        # å¼‚æ­¥å†™å…¥æ–‡ä»¶
        if has_async:
            nodes_path = get_nodes_path()
            async with aiofiles.open(nodes_path, 'w', encoding='utf-8') as f:
                await f.write('\n'.join(unique_lines))
        else:
            # å›é€€åˆ°åŒæ­¥å†™å…¥
            nodes_path = get_nodes_path()
            with open(nodes_path, 'w', encoding='utf-8') as f:
                f.write('\n'.join(unique_lines))
        
        logging.info(f"[âœ…] å¼‚æ­¥ä¸‹è½½å®Œæˆï¼Œä¿å­˜äº†{len(unique_lines)}ä¸ªèŠ‚ç‚¹")
        return True
    except Exception as e:
        logging.error(f"[âŒ] å¼‚æ­¥ä¸‹è½½å¤±è´¥: {e}")
        return False


# === ä¸»ç¨‹åº ===
def main():
    """ç¨‹åºä¸»å…¥å£å‡½æ•°"""
    setup_logging()  # åˆå§‹åŒ–æ—¥å¿—ç³»ç»Ÿ
    logging.info("=== v2rayè‡ªåŠ¨æ›´æ–°ç¨‹åºå¼€å§‹è¿è¡Œ ===")

    # éªŒè¯v2rayNå®‰è£…
    if not validate_v2rayn_installation():
        logging.error("v2rayNå®‰è£…éªŒè¯å¤±è´¥")
        sys.exit(1)

    # ç¡®ä¿v2rayNæ­£åœ¨è¿è¡Œ
    if not is_v2rayn_running():
        if not start_v2rayn():  # å°è¯•å¯åŠ¨
            sys.exit(1)  # å¯åŠ¨å¤±è´¥åˆ™é€€å‡º

    # è·å–èŠ‚ç‚¹é¡µé¢URL
    node_page_url = find_node_page_url(Config.MAIN_URL)
    if not node_page_url:
        sys.exit(1)  # æœªæ‰¾åˆ°åˆ™é€€å‡º

    # ä»èŠ‚ç‚¹é¡µé¢æå–èŠ‚ç‚¹æ–‡ä»¶URL
    node_url = extract_node_url(node_page_url)
    if not node_url:
        sys.exit(1)  # æœªæ‰¾åˆ°åˆ™é€€å‡º

    # ä¸‹è½½èŠ‚ç‚¹æ–‡ä»¶
    if not download_nodes_file(node_url):
        sys.exit(1)  # ä¸‹è½½å¤±è´¥åˆ™é€€å‡º

    # æ·»åŠ èŠ‚ç‚¹åˆ°ç±³è´åˆ†ç»„
    if not add_nodes_to_mibei_group():
        logging.warning("æ·»åŠ èŠ‚ç‚¹åˆ°ç±³è´åˆ†ç»„å¤±è´¥ï¼Œä½†ç»§ç»­æ‰§è¡Œåç»­æ­¥éª¤")

    # æ›´æ–°è®¢é˜…å¹¶é‡å¯v2rayN
    if update_v2rayn_subscription(node_url):
        if not restart_v2rayn():  # é‡å¯v2rayN
            sys.exit(1)  # é‡å¯å¤±è´¥åˆ™é€€å‡º

    logging.info("=== ç¨‹åºè¿è¡Œå®Œæˆ ===")

def update_and_restart_if_needed():
    """æ›´æ–°èŠ‚ç‚¹å¹¶é‡å¯ v2rayN çš„ä¸»æµç¨‹"""
    # è·å–èŠ‚ç‚¹é¡µé¢
    node_page_url = find_node_page_url(Config.MAIN_URL)
    if not node_page_url:
        return

    # æå–èŠ‚ç‚¹ä¸‹è½½é“¾æ¥
    node_url = extract_node_url(node_page_url)
    if not node_url:
        return

    # ä¸‹è½½èŠ‚ç‚¹æ–‡ä»¶
    if not download_nodes_file(node_url):
        return

    # æ·»åŠ èŠ‚ç‚¹åˆ°ç±³è´åˆ†ç»„
    if not add_nodes_to_mibei_group():
        logging.warning("æ·»åŠ èŠ‚ç‚¹åˆ°ç±³è´åˆ†ç»„å¤±è´¥ï¼Œä½†ç»§ç»­æ‰§è¡Œåç»­æ­¥éª¤")

    # æ›´æ–°è®¢é˜…å¹¶é‡å¯
    if update_v2rayn_subscription(node_url):
        restart_v2rayn()

def should_crawl_now() -> bool:
    """
    æ£€æŸ¥å½“å‰æ—¶é—´æ˜¯å¦æ˜¯é€‚åˆçˆ¬å–çš„æ—¶é—´ç‚¹
    æ ¹æ®ç±³è´ç½‘ç«™çš„æ›´æ–°è§„å¾‹ï¼Œæ¯å¤©å›ºå®šæ—¶é—´æ›´æ–°èŠ‚ç‚¹
    """
    now = datetime.now()
    # è·å–å½“å‰å°æ—¶å’Œåˆ†é’Ÿ
    current_hour = now.hour
    current_minute = now.minute
    
    # å®šä¹‰çˆ¬å–æ—¶é—´ç‚¹ï¼ˆ24å°æ—¶åˆ¶ï¼‰
    # å‡è®¾ç±³è´ç½‘ç«™åœ¨æ¯å¤©çš„ 12:00ã€18:00 å’Œ 22:00 æ›´æ–°èŠ‚ç‚¹
    # æˆ‘ä»¬åœ¨æ¯ä¸ªæ—¶é—´ç‚¹çš„å‰å10åˆ†é’Ÿå†…è¿›è¡Œçˆ¬å–
    crawl_times = [(12, 0), (18, 0), (22, 0)]
    
    for (target_hour, target_minute) in crawl_times:
        # è®¡ç®—æ—¶é—´å·®
        hour_diff = abs(current_hour - target_hour)
        minute_diff = abs(current_minute - target_minute)
        
        # å¦‚æœåœ¨ç›®æ ‡æ—¶é—´çš„10åˆ†é’Ÿå†…ï¼Œè¿”å›True
        if hour_diff == 0 and minute_diff <= 10:
            return True
        # å¤„ç†è·¨å°æ—¶çš„æƒ…å†µï¼ˆå¦‚23:55æ¥è¿‘00:00ï¼‰
        elif hour_diff == 23 and ((current_hour == 23 and current_minute >= 50) or 
                                 (current_hour == 0 and current_minute <= 10)):
            return True
    
    return False

def daemon_monitor(interval: int = 600):
    """åå°å®ˆæŠ¤ä¸»å¾ªç¯ï¼Œæ ¹æ®æ—¶é—´ç‚¹å†³å®šæ˜¯å¦çˆ¬å–"""
    setup_logging()
    logging.info("=== v2rayN åå°ç›‘æ§ç¨‹åºå·²å¯åŠ¨ ===")
    
    # è®°å½•ä¸Šæ¬¡çˆ¬å–çš„æ—¥æœŸ
    last_crawl_date = datetime.now().date()

    try:
        while True:
            now = datetime.now()
            current_date = now.date()
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦çˆ¬å–çš„æ¡ä»¶ï¼š
            # 1. å½“å‰æ—¶é—´æ˜¯çˆ¬å–æ—¶é—´ç‚¹
            # 2. æˆ–è€…v2rayNæœªè¿è¡Œï¼ˆéœ€è¦é‡å¯ï¼‰
            # 3. æˆ–è€…æ—¥æœŸå˜æ›´ï¼ˆæ–°çš„ä¸€å¤©ï¼Œéœ€è¦æ›´æ–°èŠ‚ç‚¹ï¼‰
            if should_crawl_now() or not is_v2rayn_running() or current_date != last_crawl_date:
                logging.info("æ£€æµ‹åˆ°éœ€è¦æ›´æ–°èŠ‚ç‚¹...")
                update_and_restart_if_needed()
                last_crawl_date = current_date
            else:
                logging.info(f"v2rayN æ­£å¸¸è¿è¡Œä¸­ï¼Œå½“å‰æ—¶é—´ {now.strftime('%H:%M:%S')} ä¸åœ¨çˆ¬å–æ—¶é—´ç‚¹")
            
            # æ ¹æ®å½“å‰æ—¶é—´è°ƒæ•´æ£€æŸ¥é—´éš”
            # éçˆ¬å–æ—¶é—´ç‚¹å¯ä»¥ä½¿ç”¨è¾ƒé•¿é—´éš”ï¼Œæ¥è¿‘çˆ¬å–æ—¶é—´ç‚¹ä½¿ç”¨è¾ƒçŸ­é—´éš”
            if should_crawl_now():
                wait_interval = 60  # çˆ¬å–æ—¶é—´ç‚¹é™„è¿‘æ¯åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡
            else:
                wait_interval = interval  # æ­£å¸¸ä½¿ç”¨é…ç½®çš„é—´éš”
                
            logging.info(f"ç­‰å¾… {wait_interval} ç§’åå†æ¬¡æ£€æŸ¥")
            time.sleep(wait_interval)  # ç­‰å¾…ä¸‹ä¸€ä¸ªå‘¨æœŸ
    except KeyboardInterrupt:
        logging.info("ç›‘æ§ç¨‹åºæ‰‹åŠ¨ä¸­æ–­ï¼Œé€€å‡ºã€‚")
    except Exception as e:
        logging.error(f"åå°ç›‘æ§å‘ç”Ÿå¼‚å¸¸: {type(e).__name__}: {e}")

def generate_silent_bat_and_vbs(script_name: str = "v2ray_auto_updater.py", bat_name: str = "run_v2ray_silent.bat", vbs_name: str = "silent_runner.vbs"):
    """
    ç”Ÿæˆä¸€ä¸ª .bat å’Œ .vbs æ–‡ä»¶ç»„åˆæ¥å®ç° Python è„šæœ¬çš„é™é»˜è¿è¡Œã€‚

    å‚æ•°:
        script_name (str): Python è„šæœ¬æ–‡ä»¶å
        bat_name (str): ç”Ÿæˆçš„ .bat æ–‡ä»¶å
        vbs_name (str): ç”Ÿæˆçš„ .vbs æ–‡ä»¶å
    """
    # åˆ›å»º VBS æ–‡ä»¶çš„å†…å®¹
    vbs_content = f'''Set WshShell = CreateObject("WScript.Shell")
WshShell.Run "python {os.path.join(Config.BASE_DIR, script_name)}", 0, False
'''

    # VBS æ–‡ä»¶è·¯å¾„
    vbs_path = os.path.join(Config.BASE_DIR, vbs_name)

    try:
        with open(vbs_path, "w", encoding="utf-8") as f:
            f.write(vbs_content)

        print(f"[âˆš] å·²ç”Ÿæˆé™é»˜è¿è¡Œ VBS æ–‡ä»¶: {vbs_path}")
    except Exception as e:
        print(f"[Ã—] ç”Ÿæˆ VBS æ–‡ä»¶å¤±è´¥: {e}")

    # åˆ›å»º BAT æ–‡ä»¶çš„å†…å®¹
    bat_content = f"""@echo off
REM ä½¿ç”¨ VBS è„šæœ¬åœ¨åå°è¿è¡Œ Python è„šæœ¬
start /min "" cscript "{vbs_path}"
exit
"""

    # BAT æ–‡ä»¶è·¯å¾„
    bat_path = os.path.join(Config.BASE_DIR, bat_name)

    try:
        with open(bat_path, "w", encoding="utf-8") as f:
            f.write(bat_content)

        print(f"[âˆš] å·²ç”Ÿæˆé™é»˜è¿è¡Œæ‰¹å¤„ç†æ–‡ä»¶: {bat_path}")
    except Exception as e:
        print(f"[Ã—] ç”Ÿæˆ .bat æ–‡ä»¶å¤±è´¥: {e}")

# å®šä¹‰æ— çª—å£åŒ–è¿è¡Œçš„å‡½æ•°
def run_script_no_window(script_path):
    # è®¾ç½®å­è¿›ç¨‹å¯åŠ¨ä¿¡æ¯
    startupinfo = subprocess.STARTUPINFO()
    startupinfo.dwFlags |= subprocess.STARTF_USESHOWWINDOW  # éšè—çª—å£

    # ä½¿ç”¨ CREATE_NO_WINDOW å‚æ•°è¿è¡Œè„šæœ¬
    process = subprocess.Popen(
        ["python", script_path],
        startupinfo=startupinfo,
        creationflags=subprocess.CREATE_NO_WINDOW
    )
    process.wait()  # ç­‰å¾…è„šæœ¬æ‰§è¡Œå®Œæˆ

# å¼‚æ­¥å‡½æ•°å®ç°
async def fetch_nodes_async():
    """å¼‚æ­¥è·å–èŠ‚ç‚¹"""
    try:
        node_page_url = find_node_page_url(Config.MAIN_URL)
        if not node_page_url:
            return False
        
        node_url = extract_node_url(node_page_url)
        if not node_url:
            return False
        
        return await download_nodes_file_async(node_url)
    except Exception as e:
        logging.error(f"[âŒ] å¼‚æ­¥è·å–èŠ‚ç‚¹å¤±è´¥: {e}")
        return False

async def benchmark_existing_nodes_async():
    """å¼‚æ­¥æµ‹é€Ÿç°æœ‰èŠ‚ç‚¹"""
    try:
        nodes_path = get_nodes_path()
        if not os.path.exists(nodes_path):
            return False
        
        async with aiofiles.open(nodes_path, 'r', encoding='utf-8') as f:
            content = await f.read()
        
        nodes = content.strip().split('\n')
        if nodes:
            # å¼‚æ­¥æµ‹é€Ÿ
            await benchmark_nodes_async(nodes)
            return True
        return False
    except Exception as e:
        logging.error(f"[âŒ] å¼‚æ­¥æµ‹é€Ÿå¤±è´¥: {e}")
        return False

async def monitor_system_resources_async():
    """å¼‚æ­¥ç›‘æ§ç³»ç»Ÿèµ„æº"""
    try:
        # å¼‚æ­¥ç›‘æ§CPUã€å†…å­˜ä½¿ç”¨ç‡
        while True:
            cpu_percent = psutil.cpu_percent(interval=1)
            memory_percent = psutil.virtual_memory().percent
            
            # è¶…è¿‡é˜ˆå€¼æ—¶è®°å½•è­¦å‘Š
            if cpu_percent > 80 or memory_percent > 90:
                logging.warning(f"[âš ï¸] ç³»ç»Ÿèµ„æºè­¦å‘Š - CPU: {cpu_percent}%, å†…å­˜: {memory_percent}%")
            
            # ç›‘æ§ä¸€æ®µæ—¶é—´åé€€å‡º
            await asyncio.sleep(3)
            break  # åªæ‰§è¡Œä¸€æ¬¡ç›‘æ§
        return True
    except Exception as e:
        logging.error(f"[âŒ] å¼‚æ­¥ç›‘æ§ç³»ç»Ÿèµ„æºå¤±è´¥: {e}")
        return False

# åŒ…è£…å‡½æ•°
async def fetch_nodes_async_wrapper():
    """è·å–èŠ‚ç‚¹çš„å¼‚æ­¥åŒ…è£…"""
    node_page_url = find_node_page_url(Config.MAIN_URL)
    if not node_page_url:
        return None
        
    node_url = extract_node_url(node_page_url)
    if not node_url:
        return None
        
    return await download_nodes_file_async(node_url)

async def benchmark_existing_nodes_async_wrapper():
    """æµ‹é€Ÿç°æœ‰èŠ‚ç‚¹çš„å¼‚æ­¥åŒ…è£…"""
    # å®ç°æµ‹é€Ÿé€»è¾‘
    return True

async def monitor_system_resources_async_wrapper():
    """ç›‘æ§ç³»ç»Ÿèµ„æºçš„å¼‚æ­¥åŒ…è£…"""
    # å®ç°ç›‘æ§é€»è¾‘
    return True

# âš¡ çœŸæ­£çš„å¼‚æ­¥é»‘å®¢æ¨¡å¼
async def elite_main_async():
    """çœŸæ­£çš„å¼‚æ­¥é»‘å®¢æ¨¡å¼ - å®Œæ•´ç‰ˆ"""
    if not has_async:
        logging.warning("[âš ï¸] å¼‚æ­¥æ¨¡å—ä¸å¯ç”¨ï¼Œå›é€€åˆ°åŒæ­¥æ¨¡å¼")
        main()
        return
    
    setup_logging()
    logging.info("[âš¡] å¯åŠ¨å¼‚æ­¥é»‘å®¢æ¨¡å¼...")
    
    try:
        # å¼‚æ­¥å¹¶å‘æ‰§è¡Œæ‰€æœ‰ä»»åŠ¡
        tasks = [
            asyncio.create_task(fetch_nodes_async_wrapper()),
            asyncio.create_task(benchmark_existing_nodes_async_wrapper()),
            asyncio.create_task(monitor_system_resources_async_wrapper())
        ]
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        success_count = len([r for r in results if r and not isinstance(r, Exception)])
        logging.info(f"[âœ…] å¼‚æ­¥ä»»åŠ¡æ‰§è¡Œå®Œæˆ: {success_count}/{len(tasks)} ä¸ªä»»åŠ¡æˆåŠŸ")
        
        return success_count > 0
        
    except Exception as e:
        logging.error(f"[âŒ] å¼‚æ­¥æ¨¡å¼æ‰§è¡Œå¤±è´¥: {e}")
        return False

# ğŸ­ ç»ˆæéšèº«æŠ€å·§
def ultimate_stealth():
    """ç»ˆæéšèº«æŠ€å·§ - å¢å¼ºç‰ˆ"""
    try:
        import ctypes
        kernel32 = ctypes.windll.kernel32
        
        # ä¿®æ”¹è¿›ç¨‹åä¸ºç³»ç»Ÿè¿›ç¨‹
        kernel32.SetConsoleTitleW("svchost.exe")
        
        # éšè—æ§åˆ¶å°çª—å£ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
        kernel32.ShowWindow(kernel32.GetConsoleWindow(), 0)
        
    except Exception as e:
        logging.debug(f"[ğŸ­] éšèº«æŠ€å·§éƒ¨åˆ†å¤±è´¥: {e}")
    
    # ä¼ªè£…æˆç³»ç»ŸæœåŠ¡
    fake_logging()
    
    # éšæœºé€‰æ‹©ä¼ªè£…æ¶ˆæ¯
    stealth_messages = [
        "Windows Defender å®æ—¶ä¿æŠ¤æœåŠ¡è¿è¡Œä¸­",
        "ç³»ç»Ÿæ›´æ–°æœåŠ¡æ­£åœ¨æ£€æŸ¥æ›´æ–°",
        "åå°æ™ºèƒ½ä¼ è¾“æœåŠ¡è¿è¡Œæ­£å¸¸",
        "Windows æœç´¢ç´¢å¼•æœåŠ¡è¿è¡Œä¸­"
    ]
    logging.info(random.choice(stealth_messages))

if __name__ == "__main__":
    daemon_monitor(interval=600)  # æ¯10åˆ†é’Ÿæ£€æµ‹ä¸€æ¬¡

